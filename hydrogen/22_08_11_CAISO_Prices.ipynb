{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpfFW2ic_lg0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### \n",
    "###   Parse data from CAISO website using my credentials\n",
    "###   Login: yurymaximov@berkeley.edu   Password: vodka8Pivo_\n",
    "###\n",
    "###\n",
    "###   Input: \n",
    "###     date_start - start time for RTM/DAM market price analysis (format: '2022-07-01')\n",
    "###     days   - days to analyse (format: 31, i.e. from July 1st to July 31st of 2022)\n",
    "###\n",
    "###   Output:\n",
    "###     5 mins schedule of locational marginal prices for a given time interval\n",
    "###\n",
    "###   Abbreviations:\n",
    "###     DAM - day ahead market\n",
    "###     RTM - real time market (5 minutes schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpz0bSjJMQ98",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## User input\n",
    "\n",
    "# Start date for the analysis\n",
    "date_start = '2022-02-01'\n",
    "\n",
    "# Days (interval: date_start to date_start + days)\n",
    "days = 7\n",
    "\n",
    "# Directory for datasets\n",
    "root_path = 'gdrive/My Drive/TechnoEconomics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rq1vCHl_vye",
    "outputId": "805282c7-86ef-453a-a1e6-1c5b387573af",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "## Import required libraries and APIs\n",
    "\n",
    "import glob\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "from dateutil import rrule\n",
    "from datetime import datetime, timedelta, date\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "## Mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w85g8UFjArde",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Convert the date com internally compatible format\n",
    "##\n",
    "## TODO: date to iso\n",
    "def get_date(start_date, numofdays: int):\n",
    "    now = date.fromisoformat(start_date)\n",
    "    end_date = now + timedelta(days=numofdays)\n",
    "\n",
    "    listofdays = rrule.rrule(rrule.DAILY, dtstart=now, until=end_date)\n",
    "    listofdays = list(map(str, listofdays))\n",
    "    listofdays = list(\n",
    "        map(lambda x: x.replace('-', '').replace(' ', 'T').rstrip(listofdays[0][14:]) + '00:00-0000', listofdays))\n",
    "    return listofdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhKMrqERA7RC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##  Concatenate all data and write as a single file\n",
    "def concate_all(path):\n",
    "    all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "    li = []\n",
    "    print(all_files)\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0, low_memory=False)\n",
    "        li.append(df)\n",
    "\n",
    "    frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "    \n",
    "    ## need to check\n",
    "    frame.to_csv(root_path+'multi.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozvpBwdxCUhC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Function benchmarker wrapper\n",
    "def benchmark(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        func(*args, **kwargs)\n",
    "        print('success', *args)\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-M2CQIrCbl2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## CAISO Local marginal prices (Real time market = RTM)\n",
    "def get_prices(nodename, startdate, enddate):\n",
    "    rsp = requests.get(\n",
    "        f'http://oasis.caiso.com/oasisapi/SingleZip?queryname=PRC_INTVL_LMP&startdatetime={startdate}&enddatetime={enddate}&version=1&market_run_id=RTM&node={nodename}&resultformat=6',\n",
    "        timeout=335)\n",
    "\n",
    "    z = zipfile.ZipFile(io.BytesIO(rsp.content))\n",
    "    csv = z.open(z.namelist()[0])\n",
    "    df = pd.read_csv(csv)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVqDi48kCpib",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## CAISO Local marginal prices (Day ahead market = DAM)\n",
    "def get_dam(nodename, startdate, enddate):\n",
    "    # http://oasis.caiso.com/oasisapi/SingleZip?queryname=PRC_LMP&market_run_id=DAM&startdatetime=20210101T08%3A00-0000&enddatetime=20210102T08%3A00-0000&version=1&node=CAPTJACK_5_N003&resultformat=6\n",
    "\n",
    "    rsp = requests.get(\n",
    "        f'http://oasis.caiso.com/oasisapi/SingleZip?queryname=PRC_LMP&startdatetime={startdate}&enddatetime={enddate}&version=1&market_run_id=DAM&node={nodename}&resultformat=6')\n",
    "    z = zipfile.ZipFile(io.BytesIO(rsp.content))\n",
    "    csv = z.open(z.namelist()[0])\n",
    "    df = pd.read_csv(csv)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ap8PXLYgCz7-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Additional node information (any existing, RTM market)\n",
    "def get_node_info(name, dates, path):\n",
    "    list_of_csv = []\n",
    "    for day in range(len(dates) - 1):\n",
    "        time.sleep(6)\n",
    "        df = get_prices(name, dates[day], dates[day + 1])\n",
    "        print(df.head())\n",
    "        list_of_csv.append(df)\n",
    "    print(len(list_of_csv))\n",
    "\n",
    "    df_f = pd.concat(list_of_csv, ignore_index=True)\n",
    "    print('Success')\n",
    "    df_f.to_csv(f'{path}/{name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "edL4iSkY6JZw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S10S1-OHDD68",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymrmEMw6DXD8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Additional node information (any existing, DAM market)\n",
    "def get_node_DAM(name, dates, path):\n",
    "    list_of_csv = []\n",
    "    for day in range(len(dates) - 1):\n",
    "        time.sleep(6)\n",
    "        df = get_dam(name, dates[day], dates[day + 1])\n",
    "        print(df.head())\n",
    "        list_of_csv.append(df)\n",
    "    print(len(list_of_csv))\n",
    "\n",
    "    df_f = pd.concat(list_of_csv, ignore_index=True)\n",
    "    print('Success')\n",
    "    df_f.to_csv(f'{path}/{name}_DAM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORFXuT10D1a3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get CO2 emissions information\n",
    "def getco2(listofdates):\n",
    "    for dt in listofdates:\n",
    "        datetoreq = dt[:8]\n",
    "        print(datetoreq)\n",
    "        rsp = requests.get(f'https://www.caiso.com/outlook/SP/History/{datetoreq}/co2.csv?=1659725917675')\n",
    "        df = pd.read_csv(io.StringIO(rsp.content.decode('utf-8')))\n",
    "        df = df.rename(columns={'Time': 'Date'})\n",
    "\n",
    "        df['Date'] = dt[:9] + df['Date'].astype(str)\n",
    "        # df['Date']='20210701T'+df['Date'].str.replace(',','-')\n",
    "        print('Success')\n",
    "        df.to_csv(f'outputs/{dt}.csv', index=False)\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7EEPvto0_v5n",
    "outputId": "e5d13a9c-d24f-4279-b556-65eec49a43b4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       INTERVALSTARTTIME_GMT        INTERVALENDTIME_GMT      OPR_DT  OPR_HR  \\\n",
      "0  2022-02-01T00:00:00-00:00  2022-02-01T00:05:00-00:00  2022-01-31      17   \n",
      "1  2022-02-01T00:05:00-00:00  2022-02-01T00:10:00-00:00  2022-01-31      17   \n",
      "2  2022-02-01T00:10:00-00:00  2022-02-01T00:15:00-00:00  2022-01-31      17   \n",
      "3  2022-02-01T00:15:00-00:00  2022-02-01T00:20:00-00:00  2022-01-31      17   \n",
      "4  2022-02-01T00:20:00-00:00  2022-02-01T00:25:00-00:00  2022-01-31      17   \n",
      "\n",
      "       NODE_ID_XML          NODE_ID             NODE MARKET_RUN_ID LMP_TYPE  \\\n",
      "0  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "1  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "2  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "3  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "4  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "\n",
      "  XML_DATA_ITEM    PNODE_RESMRID GRP_TYPE  POS       MW  OPR_INTERVAL  GROUP  \n",
      "0  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  4.47813             1      1  \n",
      "1  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  3.01822             2      1  \n",
      "2  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  1.82098             3      1  \n",
      "3  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  3.78616             4      1  \n",
      "4  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  4.25855             5      1  \n",
      "       INTERVALSTARTTIME_GMT        INTERVALENDTIME_GMT      OPR_DT  OPR_HR  \\\n",
      "0  2022-02-02T00:00:00-00:00  2022-02-02T00:05:00-00:00  2022-02-01      17   \n",
      "1  2022-02-02T00:05:00-00:00  2022-02-02T00:10:00-00:00  2022-02-01      17   \n",
      "2  2022-02-02T00:10:00-00:00  2022-02-02T00:15:00-00:00  2022-02-01      17   \n",
      "3  2022-02-02T00:15:00-00:00  2022-02-02T00:20:00-00:00  2022-02-01      17   \n",
      "4  2022-02-02T00:20:00-00:00  2022-02-02T00:25:00-00:00  2022-02-01      17   \n",
      "\n",
      "       NODE_ID_XML          NODE_ID             NODE MARKET_RUN_ID LMP_TYPE  \\\n",
      "0  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "1  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "2  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "3  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "4  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "\n",
      "  XML_DATA_ITEM    PNODE_RESMRID GRP_TYPE  POS       MW  OPR_INTERVAL  GROUP  \n",
      "0  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.00000             1      1  \n",
      "1  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.00000             2      1  \n",
      "2  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1 -1.19398             3      1  \n",
      "3  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.00000             4      1  \n",
      "4  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.00000             5      1  \n",
      "       INTERVALSTARTTIME_GMT        INTERVALENDTIME_GMT      OPR_DT  OPR_HR  \\\n",
      "0  2022-02-03T00:00:00-00:00  2022-02-03T00:05:00-00:00  2022-02-02      17   \n",
      "1  2022-02-03T00:05:00-00:00  2022-02-03T00:10:00-00:00  2022-02-02      17   \n",
      "2  2022-02-03T00:10:00-00:00  2022-02-03T00:15:00-00:00  2022-02-02      17   \n",
      "3  2022-02-03T00:15:00-00:00  2022-02-03T00:20:00-00:00  2022-02-02      17   \n",
      "4  2022-02-03T00:20:00-00:00  2022-02-03T00:25:00-00:00  2022-02-02      17   \n",
      "\n",
      "       NODE_ID_XML          NODE_ID             NODE MARKET_RUN_ID LMP_TYPE  \\\n",
      "0  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "1  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "2  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "3  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "4  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "\n",
      "  XML_DATA_ITEM    PNODE_RESMRID GRP_TYPE  POS   MW  OPR_INTERVAL  GROUP  \n",
      "0  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             1      1  \n",
      "1  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             2      1  \n",
      "2  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             3      1  \n",
      "3  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             4      1  \n",
      "4  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             5      1  \n",
      "       INTERVALSTARTTIME_GMT        INTERVALENDTIME_GMT      OPR_DT  OPR_HR  \\\n",
      "0  2022-02-04T00:00:00-00:00  2022-02-04T00:05:00-00:00  2022-02-03      17   \n",
      "1  2022-02-04T00:05:00-00:00  2022-02-04T00:10:00-00:00  2022-02-03      17   \n",
      "2  2022-02-04T00:10:00-00:00  2022-02-04T00:15:00-00:00  2022-02-03      17   \n",
      "3  2022-02-04T00:15:00-00:00  2022-02-04T00:20:00-00:00  2022-02-03      17   \n",
      "4  2022-02-04T00:20:00-00:00  2022-02-04T00:25:00-00:00  2022-02-03      17   \n",
      "\n",
      "       NODE_ID_XML          NODE_ID             NODE MARKET_RUN_ID LMP_TYPE  \\\n",
      "0  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "1  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "2  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "3  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "4  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "\n",
      "  XML_DATA_ITEM    PNODE_RESMRID GRP_TYPE  POS   MW  OPR_INTERVAL  GROUP  \n",
      "0  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             1      1  \n",
      "1  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             2      1  \n",
      "2  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             3      1  \n",
      "3  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             4      1  \n",
      "4  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             5      1  \n",
      "       INTERVALSTARTTIME_GMT        INTERVALENDTIME_GMT      OPR_DT  OPR_HR  \\\n",
      "0  2022-02-05T00:00:00-00:00  2022-02-05T00:05:00-00:00  2022-02-04      17   \n",
      "1  2022-02-05T00:05:00-00:00  2022-02-05T00:10:00-00:00  2022-02-04      17   \n",
      "2  2022-02-05T00:10:00-00:00  2022-02-05T00:15:00-00:00  2022-02-04      17   \n",
      "3  2022-02-05T00:15:00-00:00  2022-02-05T00:20:00-00:00  2022-02-04      17   \n",
      "4  2022-02-05T00:20:00-00:00  2022-02-05T00:25:00-00:00  2022-02-04      17   \n",
      "\n",
      "       NODE_ID_XML          NODE_ID             NODE MARKET_RUN_ID LMP_TYPE  \\\n",
      "0  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "1  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "2  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "3  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "4  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "\n",
      "  XML_DATA_ITEM    PNODE_RESMRID GRP_TYPE  POS   MW  OPR_INTERVAL  GROUP  \n",
      "0  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             1      1  \n",
      "1  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             2      1  \n",
      "2  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             3      1  \n",
      "3  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             4      1  \n",
      "4  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             5      1  \n",
      "       INTERVALSTARTTIME_GMT        INTERVALENDTIME_GMT      OPR_DT  OPR_HR  \\\n",
      "0  2022-02-06T00:00:00-00:00  2022-02-06T00:05:00-00:00  2022-02-05      17   \n",
      "1  2022-02-06T00:05:00-00:00  2022-02-06T00:10:00-00:00  2022-02-05      17   \n",
      "2  2022-02-06T00:10:00-00:00  2022-02-06T00:15:00-00:00  2022-02-05      17   \n",
      "3  2022-02-06T00:15:00-00:00  2022-02-06T00:20:00-00:00  2022-02-05      17   \n",
      "4  2022-02-06T00:20:00-00:00  2022-02-06T00:25:00-00:00  2022-02-05      17   \n",
      "\n",
      "       NODE_ID_XML          NODE_ID             NODE MARKET_RUN_ID LMP_TYPE  \\\n",
      "0  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "1  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "2  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "3  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "4  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "\n",
      "  XML_DATA_ITEM    PNODE_RESMRID GRP_TYPE  POS   MW  OPR_INTERVAL  GROUP  \n",
      "0  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             1      1  \n",
      "1  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             2      1  \n",
      "2  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             3      1  \n",
      "3  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             4      1  \n",
      "4  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             5      1  \n",
      "       INTERVALSTARTTIME_GMT        INTERVALENDTIME_GMT      OPR_DT  OPR_HR  \\\n",
      "0  2022-02-07T00:00:00-00:00  2022-02-07T00:05:00-00:00  2022-02-06      17   \n",
      "1  2022-02-07T00:05:00-00:00  2022-02-07T00:10:00-00:00  2022-02-06      17   \n",
      "2  2022-02-07T00:10:00-00:00  2022-02-07T00:15:00-00:00  2022-02-06      17   \n",
      "3  2022-02-07T00:15:00-00:00  2022-02-07T00:20:00-00:00  2022-02-06      17   \n",
      "4  2022-02-07T00:20:00-00:00  2022-02-07T00:25:00-00:00  2022-02-06      17   \n",
      "\n",
      "       NODE_ID_XML          NODE_ID             NODE MARKET_RUN_ID LMP_TYPE  \\\n",
      "0  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "1  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "2  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "3  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "4  HOLLISTR_1_N101  HOLLISTR_1_N101  HOLLISTR_1_N101           RTM      MCC   \n",
      "\n",
      "  XML_DATA_ITEM    PNODE_RESMRID GRP_TYPE  POS   MW  OPR_INTERVAL  GROUP  \n",
      "0  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             1      1  \n",
      "1  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             2      1  \n",
      "2  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             3      1  \n",
      "3  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             4      1  \n",
      "4  LMP_CONG_PRC  HOLLISTR_1_N101      ALL    1  0.0             5      1  \n",
      "7\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Get prices ++ from CAISO HOLLISTR node RTM market\n",
    "# \n",
    "get_node_info('HOLLISTR_1_N101', get_date(date_start, days), root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dADLPjeh_qFa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get prices ++ from CAISO HOLLISTR node DAM market\n",
    "#\n",
    "\n",
    "#get_node_DAM('HOLLISTR_1_N101', get_date(date_start, days), root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_m3P0IigO75b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7562b5da-905e-4f5d-9beb-cf972a81c8ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20220201\n",
      "Success\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-7f9e48a18658>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mgetco2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_date\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'2022-02-01'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m7\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;31m#print(get_date('2021-08-05',1))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# concate_all(path)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-11-56f01641e529>\u001B[0m in \u001B[0;36mgetco2\u001B[0;34m(listofdates)\u001B[0m\n\u001B[1;32m     11\u001B[0m         \u001B[0;31m# df['Date']='20210701T'+df['Date'].str.replace(',','-')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Success'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m         \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'outputs/{dt}.csv'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m         \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36mto_csv\u001B[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001B[0m\n\u001B[1;32m   3480\u001B[0m             \u001B[0mdoublequote\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdoublequote\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3481\u001B[0m             \u001B[0mescapechar\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mescapechar\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3482\u001B[0;31m             \u001B[0mstorage_options\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3483\u001B[0m         )\n\u001B[1;32m   3484\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001B[0m in \u001B[0;36mto_csv\u001B[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001B[0m\n\u001B[1;32m   1103\u001B[0m             \u001B[0mformatter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfmt\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         )\n\u001B[0;32m-> 1105\u001B[0;31m         \u001B[0mcsv_formatter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1106\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1107\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcreated_buffer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/csvs.py\u001B[0m in \u001B[0;36msave\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    241\u001B[0m             \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    242\u001B[0m             \u001B[0mcompression\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompression\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 243\u001B[0;31m             \u001B[0mstorage_options\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    244\u001B[0m         ) as handles:\n\u001B[1;32m    245\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    705\u001B[0m                 \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoding\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    706\u001B[0m                 \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 707\u001B[0;31m                 \u001B[0mnewline\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    708\u001B[0m             )\n\u001B[1;32m    709\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'outputs/20220201T00:00-0000.csv'"
     ]
    }
   ],
   "source": [
    "    getco2(get_date('2022-02-01', 7))\n",
    "    #print(get_date('2021-08-05',1))\n",
    "    # concate_all(path)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "## Hardcoded request -- prices from 2021-08-01 to 2022-07-31\n",
    "from tqdm import tqdm\n",
    "\n",
    "def my_req_int():\n",
    "    df = pd.read_csv('LMPLocations.csv')\n",
    "    names_lst = df['name'].tolist()\n",
    "\n",
    "    for name in names_lst:\n",
    "        time.sleep(6)\n",
    "        df1 = get_prices(name, '20210801T00:00-0000', '20210831T00:00-0000')\n",
    "        time.sleep(6)\n",
    "        \n",
    "        df2 = get_prices(name, '20210901T00:00-0000', '20210930T00:00-0000')\n",
    "        time.sleep(6)\n",
    "        \n",
    "        df3 = get_prices(name, '20211001T00:00-0000', '20211031T00:00-0000')\n",
    "        time.sleep(6)\n",
    "        \n",
    "        df4 = get_prices(name, '20211101T00:00-0000', '20211130T00:00-0000')\n",
    "        time.sleep(6)\n",
    "\n",
    "        df5 = get_prices(name, '20211201T00:00-0000', '20211231T00:00-0000')\n",
    "        time.sleep(6)\n",
    "\n",
    "        df6 = get_prices(name, '20220101T00:00-0000', '20220131T00:00-0000')\n",
    "        time.sleep(6)\n",
    "\n",
    "        df7 = get_prices(name, '20220201T00:00-0000', '20220228T00:00-0000')\n",
    "        time.sleep(6)\n",
    "\n",
    "        df8 = get_prices(name, '20220301T00:00-0000', '20220331T00:00-0000')\n",
    "        time.sleep(6)\n",
    "\n",
    "        df9 = get_prices(name, '20220401T00:00-0000', '20220430T00:00-0000')\n",
    "        time.sleep(6)\n",
    "\n",
    "        df10 = get_prices(name, '20220501T00:00-0000', '20220531T00:00-0000')\n",
    "        time.sleep(6)\n",
    "        \n",
    "        df11 = get_prices(name, '20220601T00:00-0000', '20220630T00:00-0000')\n",
    "        time.sleep(6)\n",
    "        \n",
    "        df12 = get_prices(name, '20220701T00:00-0000', '20220731T00:00-0000')\n",
    "        time.sleep(6)\n",
    "\n",
    "        df_f = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12], ignore_index=True)\n",
    "        print('Success')\n",
    "        df_f.to_csv(f'csv/{name}.csv', index=False)"
   ],
   "metadata": {
    "id": "_f6yowyoFmum",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}